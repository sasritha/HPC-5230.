{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f6332355",
      "metadata": {
        "id": "f6332355"
      },
      "source": [
        "# RNN, LSTM, and GRU Models for Text Classification\n",
        "This notebook demonstrates how to use different recurrent neural network architectures to perform binary sentiment classification on the IMDB dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "023a5c6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "023a5c6e",
        "outputId": "387c32d0-6081-47e9-ab70-e71b01bed1c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load IMDB dataset\n",
        "vocab_size = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Pad sequences\n",
        "maxlen = 200\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8133952b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8133952b",
        "outputId": "3e4cd603-aca7-4df9-99c8-99559ccbdfb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.6184 - loss: 0.6310 - val_accuracy: 0.7820 - val_loss: 0.4765\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 0.8423 - loss: 0.3712 - val_accuracy: 0.8328 - val_loss: 0.3948\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9068 - loss: 0.2371 - val_accuracy: 0.8216 - val_loss: 0.4173\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.9485 - loss: 0.1476 - val_accuracy: 0.8340 - val_loss: 0.4702\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.9198 - loss: 0.1981 - val_accuracy: 0.8094 - val_loss: 0.4871\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8093 - loss: 0.4869\n",
            "Simple RNN Test Accuracy: 0.8130\n"
          ]
        }
      ],
      "source": [
        "# Simple RNN model\n",
        "model_rnn = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=32, input_length=maxlen),\n",
        "    SimpleRNN(units=32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_rnn.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model_rnn.evaluate(x_test, y_test)\n",
        "print(f\"Simple RNN Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba93391",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fba93391",
        "outputId": "80810783-2e61-4b03-fcf1-cffe4df4abb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 143ms/step - accuracy: 0.6526 - loss: 0.5948 - val_accuracy: 0.8312 - val_loss: 0.3787\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - accuracy: 0.8846 - loss: 0.2894 - val_accuracy: 0.8540 - val_loss: 0.3410\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 142ms/step - accuracy: 0.9176 - loss: 0.2204 - val_accuracy: 0.8606 - val_loss: 0.3245\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 146ms/step - accuracy: 0.9435 - loss: 0.1596 - val_accuracy: 0.8596 - val_loss: 0.4112\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 146ms/step - accuracy: 0.9570 - loss: 0.1277 - val_accuracy: 0.8682 - val_loss: 0.3789\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.8561 - loss: 0.3938\n",
            "LSTM Test Accuracy: 0.8562\n"
          ]
        }
      ],
      "source": [
        "# LSTM model\n",
        "model_lstm = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=32, input_length=maxlen),\n",
        "    LSTM(units=64),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_lstm.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model_lstm.evaluate(x_test, y_test)\n",
        "print(f\"LSTM Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36e0dd3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36e0dd3b",
        "outputId": "3f5dc052-8b9a-44ec-dabb-7def66590a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 186ms/step - accuracy: 0.6553 - loss: 0.5889 - val_accuracy: 0.8514 - val_loss: 0.3443\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 185ms/step - accuracy: 0.8940 - loss: 0.2690 - val_accuracy: 0.7902 - val_loss: 0.4742\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 180ms/step - accuracy: 0.9141 - loss: 0.2206 - val_accuracy: 0.8274 - val_loss: 0.3764\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 184ms/step - accuracy: 0.9385 - loss: 0.1717 - val_accuracy: 0.8660 - val_loss: 0.3769\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 185ms/step - accuracy: 0.9623 - loss: 0.1160 - val_accuracy: 0.8624 - val_loss: 0.3884\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.8554 - loss: 0.4045\n",
            "GRU Test Accuracy: 0.8561\n"
          ]
        }
      ],
      "source": [
        "# GRU model\n",
        "model_gru = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=32, input_length=maxlen),\n",
        "    GRU(units=64),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_gru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_gru.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model_gru.evaluate(x_test, y_test)\n",
        "print(f\"GRU Test Accuracy: {test_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}